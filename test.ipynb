# üß† Model Evaluation with Multiple Scaling Methods ‚Äî Google Colab Notebook

---

## üß© Cell 1: Install and Import Necessary Libraries
```python
# Uncomment the next line if you are running on Google Colab
# !pip install pandas numpy scikit-learn matplotlib seaborn imbalanced-learn scipy

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import (
    MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler,
    QuantileTransformer, PowerTransformer, Normalizer
)
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import HistGradientBoostingClassifier
from imblearn.over_sampling import SMOTE
from scipy import stats
import warnings
warnings.filterwarnings('ignore')
```

---

## üìÇ Cell 2: Load Dataset from Google Drive (or local path)
```python
# Mount Google Drive if necessary
# from google.colab import drive
# drive.mount('/content/drive')

# Load CSV file
file_path = '/mnt/data/dataset-2_9.csv'  # Local path in your session
df = pd.read_csv(file_path)

print("‚úÖ Dataset loaded successfully!")
print("Shape:", df.shape)
df.head()
```

---

## üßº Cell 3: Data Cleaning and Preprocessing
```python
# Drop unnecessary column
if 'Sum_Phq' in df.columns:
    df.drop('Sum_Phq', axis=1, inplace=True)

# Drop duplicates and handle missing values
df.drop_duplicates(inplace=True)
df.replace(['?', 'NA', 'na', '--', 'None'], np.nan, inplace=True)

# Convert numeric-like columns to numeric
df = df.apply(pd.to_numeric, errors='ignore')

# Print info
df.info()
print("\nMissing values per column:")
print(df.isnull().sum())
```

---

## üîç Cell 4: Exploratory Data Analysis (EDA) ‚Äî Custom Heatmap
```python
plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

plt.figure(figsize=(8, 5))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
plt.title('Missing Value Heatmap')
plt.show()
```

---

## ‚öôÔ∏è Cell 5: Feature Engineering ‚Äî Example Templates
```python
# Example of feature engineering (customize if needed)
if 'age' in df.columns:
    df['age_group'] = pd.cut(df['age'], bins=[0, 20, 40, 60, 80, 100], labels=['Teen', 'Adult', 'Mid-age', 'Senior', 'Elder'])

# Convert categorical to dummy variables
df = pd.get_dummies(df, drop_first=True)

print("‚úÖ Feature engineering complete!")
```

---

## üéØ Cell 6: Feature Selection
```python
TARGET_COLUMN = 'depression'

X = df.drop(columns=[TARGET_COLUMN])
y = df[TARGET_COLUMN]

# Handle NaN by filling median values
X = X.fillna(X.median())

# Select top 10 features
selector = SelectKBest(f_classif, k=min(10, X.shape[1]))
X_selected = selector.fit_transform(X, y)
selected_features = X.columns[selector.get_support()]

print("Top selected features:")
print(selected_features)
```

---

## üîÄ Cell 7: Train-Test Split and SMOTE Balancing
```python
X_train, X_test, y_train, y_test = train_test_split(X[selected_features], y, test_size=0.2, random_state=42, stratify=y)

smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

print("Train shape:", X_train.shape)
print("Test shape:", X_test.shape)
```

---

## ‚öñÔ∏è Cell 8: Define Scaling Methods
```python
def get_scalers():
    return {
        'MinMaxScaler': MinMaxScaler(),
        'StandardScaler': StandardScaler(),
        'MaxAbsScaler': MaxAbsScaler(),
        'RobustScaler': RobustScaler(),
        'QuantileTransformer': QuantileTransformer(output_distribution='normal'),
        'PowerTransformer_YeoJohnson': PowerTransformer(method='yeo-johnson'),
        'Normalizer_L2': Normalizer(norm='l2')
    }
```

---

## ü§ñ Cell 9: Define Classifiers
```python
def get_classifiers():
    return {
        'LogisticRegression': LogisticRegression(max_iter=500),
        'RandomForest': RandomForestClassifier(random_state=42),
        'SVC': SVC(probability=True),
        'KNN': KNeighborsClassifier(),
        'HistGradientBoosting': HistGradientBoostingClassifier(random_state=42)
    }
```

---

## üßÆ Cell 10: Train and Evaluate Models for Each Scaler
```python
results = []
scalers = get_scalers()
classifiers = get_classifiers()

for scaler_name, scaler in scalers.items():
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    for clf_name, clf in classifiers.items():
        clf.fit(X_train_scaled, y_train)
        y_pred = clf.predict(X_test_scaled)

        acc = accuracy_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred, average='weighted')
        rec = recall_score(y_test, y_pred, average='weighted')
        f1 = f1_score(y_test, y_pred, average='weighted')
        try:
            roc = roc_auc_score(y_test, clf.predict_proba(X_test_scaled)[:, 1])
        except:
            roc = np.nan

        results.append({
            'Scaler': scaler_name,
            'Classifier': clf_name,
            'Accuracy': acc,
            'Precision': prec,
            'Recall': rec,
            'F1': f1,
            'ROC_AUC': roc
        })

results_df = pd.DataFrame(results)
results_df.sort_values(by='Accuracy', ascending=False, inplace=True)
results_df.head(10)
```

---

## üìä Cell 11: Visualize and Save Results
```python
plt.figure(figsize=(10, 6))
sns.boxplot(data=results_df, x='Scaler', y='Accuracy')
plt.xticks(rotation=45)
plt.title('Accuracy Comparison Across Scalers')
plt.show()

plt.figure(figsize=(10, 6))
sns.heatmap(results_df.pivot_table(index='Scaler', columns='Classifier', values='Accuracy'), annot=True, cmap='YlGnBu')
plt.title('Scaler vs Classifier Accuracy Heatmap')
plt.show()

# Save results
results_df.to_csv('scaler_classifier_results.csv', index=False)
print("‚úÖ Results saved as scaler_classifier_results.csv")
```

---

## üèÅ Cell 12: Final Summary and Conclusion
```python
best = results_df.iloc[0]
print(f"Best Scaler: {best['Scaler']}")
print(f"Best Classifier: {best['Classifier']}")
print(f"Accuracy: {best['Accuracy']:.4f}")
print(f"Precision: {best['Precision']:.4f}")
print(f"Recall: {best['Recall']:.4f}")
print(f"F1 Score: {best['F1']:.4f}")
print(f"ROC AUC: {best['ROC_AUC']:.4f}")

print("\n‚úÖ Model evaluation complete!")
```
